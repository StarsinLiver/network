# 로드 밸런서

## 부하 분산이란?

서비스 규모가 커지면 물리나 가상 서버 한 대로는 모든 서비스를 수용할 수 없게 됩니다. 서버 한대로 서비스를 제공할 수 있는 용량이 충분하더라도 서비스를 단일 서버로 구성하면 해당 서버의 애플리케이션, 운영체제, 하드웨어에 장애가 발생했을 때, 정상적인 서비스를 제공할 수 없습니다.

서비스 가용성을 높이기 위해 하나의 서비스는 보통 두 대 이상의 서버로 구성하는데 각 서버 IP 주소가 다르므로 사용자가 서비스를 호출할 때는 어떤 IP 로 서비스를 요청할 지 결정해야 합니다. 사용자에 따라 호출하는 서버의 IP 가 다르면 특정 서버에 장애가 발생했을 때, 전체 사용자에게 영향을 미치지 않아 장애 범위는 줄어들겠지만 여전히 부분적으로 서비스 장애가 발생합니다.

밑은 이런 서비스 장애의 예시입니다.

> 단일 서버를 구성하거나 서버를 이중화해 서비스 호출을 분리한 후, 서버 장애에 따라 서비스 장애가 발생한다.

![alt text](./image/image247.png)

이런 문제점을 해결하기 위해 L4나 L7 스위치라는 로드 밸런서 (Load Balancer)를 사용합니다. 로드 밸런서에는 동일한 서비스를 하는 다수의 서버가 등록되고 사용자로부터 서비스 요청이 오면 로드 밸런서가 받아 사용자별로 다수의 서버에 서비스 요청을 분산시켜 부하를 분산합니다. 대규모 서비스 제공을 위해 이런 로드 밸런서는 필수 서비스입니다.

로드 밸런서에서는 서비스를 위한 가상 IP (VIP)를 하나 제공하고 사용자는 각 서버의 개별 IP 주소가 아닌 동일한 가상 IP를 통해 각 서버로 접근합니다.

이 외에도 로드 밸런서는 각 서버의 서비스 상태를 체크해 서비스가 가능한 서버로만 사용자의 요청을 분산하므로 서버에서 장애가 발생하더라도 기존 요청을 분산하여 다른 서버에 서비스를 제공할 수 있습니다.

> 로드 밸런서를 통한 부하 분산 및 서비스 가용성 확보

![alt text](./image/image248.png)

```
참조 : FWLB

서버에 대한 부하 분산뿐만 아니라 방화벽을 액티브-액티브로 구성하기 위해 로드 밸런서를 사용하기도 합니다.
서버 부하 분산을 SLB(Server Load Balancing) , 방화벽 부하분산을 FWLB (FireWall Load Balancing) 라고 합니다.

방화벽은 자신을 통과한 패킷에 대해 세션을 관리하는 테이블을 갖고 있습니다. 즉, 방화벽을 통과하는 패킷에
대해서는 방화벽 정책을 확인해 허용되는 정책이면 방화벽을 통과시키면서 그 정보를 세션 테이블에 기록합니다.

응답 패킷은 방화벽 정책을 확인하는 것이 아니라 세션 테이블에서 해당 패킷을 먼저 조회합니다.
세션 테이블에 있는 응답 패킷이라면 이미 정책에서 허용된 패킷이므로 방화벽을 바로 통과할 수 있습니다.

하지만 세션 테이블에 응답 패킷이 없다면 요청한 적이 없는 패킷에 대한 응답으로 간주하고 공격성으로 판단해
해당 패킷을 폐기 (Drop) 됩니다. 이런 경우는 출발지와 목적지 간 경로가 두 개 이상이 있어 비대칭 경로가
만들어질 대도 발생할 수 있습니다.

방화벽 장비를 이중화할 경우, 이런 비대칭 동작으로 인해 방화벽이 정상적으로 동작하지 않을 수 있습니다.
이런 문제를 해결하고 동시에 이중화된 방화벽을 모두 사용하기 위해 FWLB가 사용됩니다.

FWLB가 세션을 인식하고 일정한 규칙을 이용하여 방화벽 세션을 분산하는데 한번 방화벽을 지나갔던 세션이
다시 같은 방화벽을 거치도록 트래픽을 분산합니다.

FWLB를 사용하더라도 방화벽에 장애가 발생하는 경우를 대비하기 위해 방화벽에서 설정이 필요합니다. 방화벽끼리
세션 테이블을 동기화하거나 방화벽에서 첫 번재 패킷이 SYN이 아니어도 허용하는 기능을 사용해 방화벽의 장애로
인해 기존 세션 테이블에 없던 트래픽이 들어오더라도 처리할 수 있도록 설정해야 합니다.
```

## 부하 분산 방법

로드 밸런서는 부하를 다수의 장비로 어떻게 분산시킬까요? 앞에서 다룬 LACP는 두 개 이상의 인터페이스를 하나의 논리 인터페이스로 묶어 회선의 부하를 분산시켰습니다. LACP는 다수의 물리 인터페이스를 하나의 논리 인터페이스로 구성하기 위해 LACP를 위한 가상의 MAC 주소를 만들게 됩니다 .

로드 밸런서도 이와 유사하게 부하를 다수의 장비에 분산시키기 위해 가상 IP 주소를 갖게 됩니다. 로드 밸런서도 이와 유사하게 부하를 다수의 장비에 분산시키기 위해 가상 IP 주소를 갖게 됩니다. 이 IP 주소는 가상 IP 주소이므로 VIP(Virtual IP)라고도 하고 서비스를 위해 사용되는 IP 주소이므로 서비스 IP 주소라고도 합니다.

가상 IP 주소가 있다면 실제 IP도 있을 것입니다. 각 서버의 실제 IP 를 리얼 (Real)IP 라고 하고 로드밸런서의 가상 IP에 실제 서버들이 바인딩(Binding) 됩니다. 실무에서는 가상 IP는 VIP라고도 부르고 로드 밸런서에 바인딩 되어 있는 서버 IP는 리얼 IP 또는 RIP 라고 합니다.

정리하면 로드 밸런서에는 서비스를 제공하는 서버의 IP인 리얼 IP 와 로드 밸런서에서 서비스를 대표하는 VIP가 있습니다. VIP에는 리얼 IP가 바인딩되어 ㅣㅇㅆ고 사용자가 VIP로 서비스를 요청하면 해당 VIP에 연결된 리얼 IP로 해당 요청을 전달합니다.

> 부하 분산 예

![alt text](./image/image249.png)

현재 서버 세 대가 있습니다. 서버의 각 IP 주소는 10.10.20.11 , 10.10.20.12 , 10.10.20.13 입니다.

서버 1번은 http , 3번은 https 서비스 데몬이 동작하고 서버 2번만 http 와 https 서비스 데몬 모두 동작합니다. 사용자가 http와 https 서비스로 접근하기 위한 VIP 주소인 10.10.10.1이 로드밸런서에 설정되어 있습니다.

VIP에는 사용자의 서비스 요청이 들어올 때 어느 서버로 요청을 전달할 것인지 부하 분산 그룹을 설정합니다. 여기서 HTTP 서비스는 서버 1번과 2번으로 HTTPS 서비스는 서버 2번과 3번으로 부하 분산 그룹이 있습니다.

로드 밸런서에서 부하 분산을 위한 그룹을 만들 때는 앞의 예제처럼 OSI 3계층 정보인 IP 주소뿐만 아니라 4계층 정보인 서비스 포트까지 지정해 만듭니다. 그래서 로드 밸런서를 L4 스위치라고 합니다.

7계층 정보까지 확인해 처리하는 기능이 포함되어 있는 경우도 있어 L7스위치라고도 하지만 보통 로드 밸런서를 L4 스위치라고 부릅니다.

앞의예제에서는 HTTP 와 HTTPS 서비스와 대해 각 동일한 VIP를 사용했지만 서로 다른 VIP로도 구성할 수 있습니다. 또한, 로드 밸런서의 VIP에 설정된 서비스 포트와 실제 서버의 서비스 포트는 반드시 같을 필요가 없습니다. 즉, 실제 서버에서는 서비스 포트 8080으로 웹 서비스를 수행하면서 VIP에서는 일반 HTTP 서비스 포트인 80으로 설정할 수 있습니다.

이렇게 되면 사용자는 VIP의 80 서비스 포트로 접근하고 로드 밸런서에서는 해당 서비스 요청을 실제 서버의 8080서비스 포트로 포트 변경까지 함께 수행하게 됩니다.

> 동일한 Real IP에서 서비스 포트마다 VIP를 다르게 설정할 수 있고 Real IP 의 서비스 포트와 VIP 포트도 서로 다르게 설정할 수 있다.

![alt text](./image/image250.png)

## 헬스 체크

로드 밸런서에서는 부하 분산을 하는 각 서버의 서비스를 주기적으로 헬스 체크 (Health Check)해 정상적인 서비스 쪽으만 부하를 분산하고 비정상적인 서버는 서비스 그룹에서 제외해 트래픽을 보내지 않습니다. 서비스 그룹에서 제외된 후에도 헬스 체크를 계속 수행해 다시 정상으로 확인되면 서비스 그룹에 해당 장비를 다시 넣어 트래픽이 서버 쪽으로 보내지도록 해줍니다.

### 1. 헬스 체크 방식

로드 밸런서는 다양한 헬스 체크 방식으로 서버의 서비스 정상 여부를 판단할 수 있습니다.

#### ICMP

VIP에 연결된 리얼 서버에 대해 ICMP(ping)로 헬스 체크를 수행하는 방법입니다. 단순히 서버가 살아있는지 여부만 체크하는 방법이므로 잘 사용하지 않습니다.

#### TCP 서비스 포트

가장 기본적인 헬스 체크 방법은 로드 밸런서에 설정된 서버의 서비스 포트를 확인하는 것입니다. 즉, 로드 밸런서에서 서버의 서비스 포트 2000번을 등록했다면 로드 밸런서에서는 리얼 IP 의 2000번 포트로 SYN을 보내고 해당 리얼 IP를 가진 서버로부터 SYN , ACK 를 받으면 서버에서 다시 ACK로 응답하고 FIN을 보내 헬스 체크를 종료합니다. 서비스 포트를 이용해 헬스 체크를 할 때는 실제 서비스 포트가 아닌 다른 서비스 포트로도 가능합니다.

![alt text](./image/image251.png)

#### TCP 서비스 포트 : Half Open

일반 TCP 서비스 포트를 확인할 때는 SYN/SYN , ACK/ACK까지 정상적인 3방향 핸드셰이크를 거치게 됩니다. 헬스 체크로 인한 부하를 줄이거나 정상적인 종료 방식보다는 빨리 헬스 체크 세션을 끊기 위해 정상적인 3방향 핸드셰이크와 4방향 핸드셰이크가 아닌 TCP Half Oepn (절반 개방) 방식을 사용하기도 합니다.

TCP Half Oepn 방식은 초기의 3방향 핸드셰이크와 동일하게 SYN을 보내고 SYN , ACK를 받지만 이후 ACK 대신 RST를 보내 세션을 끊습니다.

![alt text](./image/image252.png)

#### HTTP 상태 코드

웹서비스를 할 때, 서비스 포트까지는 TCP로 정상적으로 열리지만 웹 서비스에 대한 응답을 정상적으로 해주지는 못하는 경우가 있습니다.

이때 로드밸런서의 헬스 체크 방식 중 HTTP 상태 코드를 확인하는 방식으로 로드 밸런서가 서버로 3방향 핸드셰이크를 거치고 나서 HTTP를 요청해 정상적인 상태 코드 (200 OK)를 응답하는지 여부를 체크해 헬스 체크를 수행할 수 있습니다.

![alt text](./image/image253.png)

#### 콘텐츠 확인 (문자열 확인)

로드 밸런서에서 서버로 콘텐츠를 요청하고 응답받은 내용을 확인하여 지정된 콘텐츠가 정상적으로 응답했는지 여부를 확인하는 헬스 체크 방법도 있습니다. 보통 특정 웹페이지를 호출해 사전해 지정한 문자열이 해당 웹페이지 내에 포함 되어 잇는지를 체크하는 기능입니다.

이 헬스 체크 방식을 사용하면 로드 밸런서에서 직접 관리하는 서버의 상태뿐만아니라 해당 서버의 백엔드의 상태를 해당 웹 페이지로 체크할 수 있습니다.

다만 한 가지 유의 사항은 단순히 서버에서 응답받은 문자열만 체크하면 정상적인 요청 결과값이 아닌 문자열만 체크하므로 비정상적인 에러 코드에 대한 응답인 경우라도 해당 응답 내용에 헬스 체크를 하려고 했던 문자열이 포함되어 있으면 헬스 체크를 정상으로 판단할 수 있습니다.

따라서 문자열을 이용한 헬스 체크를 수행할 때는 정상 코드 값도 중복으로 확인하거나 문자열 자체를 일반적이 아닌 특정 문자열로 지정해 결과가 정상일때만 헬스 체크가 성공할 수 있도록 해야 합니다.

```
참고 : 다양한 헬스 체크 방법

여기서 다루지 않은 다양한 헬스 체크 방법이 있습니다.
대부분의 로드 밸런서가 사전에 정의된 다양한 헬스 체크 방식을 지원하므로 서비스에 적합한
헬스 체크 방식을 선택하면 됩니다.

1. F5 LTM을 통한 헬스 체크
2. Citrix NetScaler 를 통한 헬스 체크 등
```

### 2. 헬스 체크 주기와 타이머

헬스 체크 방법 외에 헬스 체크의 주요 고려사항인 헬스 체크 주기에 대해 알아보자. 헬스 체크 주기를 볼 때는 응답 시간, 시도 횟수, 타임아웃 등 다양한 타이머를 함께 고려해야 한다.

- 주기(Intervel) <br/>
  로드 밸런서에서 서버로 헬스 체크 패킷을 보내는 주기<br/>
- 응답 시간(Response)<br/>
  로드 밸런서에서 서버로 헬스 체크 패킷을 보내고 응답을 기다리는 시간<br/>
  해당 시간까지 응답이 오지 않으면 실패로 간주<br/>
- 시도 횟수(Retries)<br/>
  로드 밸런서에서 헬스 체크 실패 시 최대 시도 횟수<br/>
  최대 시도 횟수 이전에 성공 시 시도 횟수는 초기화 됨<br/>
- 타임아웃(Timeout)<br/>
  로드 밸런서에서 헬스 체크 실패 시 최대 대기 시간<br/>
  헬스 체크 패킷을 서버로 전송한 후 이 시간 내에 성공하지 못하면 해당 서버는 다운<br/>
- 서비스 다운 시의 주기(Dead Interval)<br/>
  서비스의 기본적인 헬스 체크 주가기 아닌, 서비스 다운 시의 헬스 체크 주기<br/>
  서비스가 죽은 상태에서 헬스 체크 주기를 별도로 더 늘릴 때 사용<br/>
  다음 그림은 헬스 체크를 수행하는 주기와 타이머를 시각화한 것이다.<br/>

![alt text](./image/image254.png)

검은색 원 모양은 로드 밸런서에서 서버로 헬스 체크 패킷을 보내는 시점을 나태낸다. 헬스 체크 주기 시간마다 로드 밸런서는 서버로 헬스 체크 패킷을 전송한다. 주기가 3초로 설정되었다면 3초마다 헬스 체크 패킷을 서버로 전송한다. 이때 원 모양 사이의 시간이 3초가 된다.

파란색 원 모양은 로드 밸런서가 보낸 헬스 체크 패킷에 대한 서버의 응답을 최대로 기다리는 시간이다. 응답 시간으로 설정된 시간 내에 서버에서 응답이 오지 않으면 로드 밸런서는 해당 헬스 체크 시도를 실패로 처리한다. 응답 시간을 1초로 주었다면 검은색 원 모양의 헬스 체크 패킷 전송 이후 1초 내에 서버에서 응답을 수신해야 한다. 이때 유의사항은 헬스 체크 패킷을 보내는 주기를 응답 시간보다 크게 설정해야하는 점이다.

## 부하 분산 알고리즘

로드 밸런서가 리얼 서버로 부하를 분산할때, 로드 밸런서에서는 사전에 설정한 분산 알고리즘을 통해 부하 분산이 이루어 집니다.

|                   부하 분산 알고리즘                   |                                                                                                                                                              |
| :----------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------------------------------------: |
|               라운드 로빈 (Round Robin)                |                         현재 구성된 장비에 부하를 순차적으로 분산함. 총 누적 세션 수는 동일하지만 활성화된 세션 수는 달라질 수 있음                          |
|           최소 접속 방식 (Least Connection)            |                                             현재 구성된 장비 중 가장 활성화된 세션 수가 적은 장비로 부하를 분산                                              |
|     가중치 기반 라운드 로빈 (Weighted Round Robin)     | 라운드 로빈 방식과 동일하지만 각 장비에 가중치를 두어 가중치가 높은 장비에 부하를 더 많이 분산함. 처리 용량이 다른 서버에 부하를 분산하기 위한 분산 알고리즘 |
| 가중치 기반 최소 접속 방식 (Weighted Least Connection) | 최소 접속 방식과 동일하지만 각 장비에 가중치를 부여해 가중치가 높은 장비에 부하를 더 많이 분산함. 처리 용량이 다른 서버에 부하를 부산하기 위한 분산 알고리즘 |
|                      해시 (Hash)                       |                                                               해시 알고리즘을 이용한 부하 분산                                                               |

### 1. 라운드 로빈

라운드 로빈 방식은 특별한 규칙 없이 현재 구성된 장비에 순차적으로 돌아가면서 트래픽을 분산합니다. 즉, 서버 세 대가 있을때 첫번째 요청은 1번 서버, 두번째 요청은 2번 서버 , 세 번째 요청은 3번 서버, 네번째 요청은 다시 1번 서버로 할당 합니다. 순차적으로 모든 장비에 분산하므로 모든 장비의 총 누적 세션 수는 같아집니다.

![alt text](./image/image255.png)

### 2. 최소 접속 방식

최소 접속 방식(Least Connection)은 서버가 가진 세션 부하를 확인해 그것에 맞게 부하를 분산하는 방식입니다. 로드 밸런서에서는 서비스 요청을 각 장비로 보내줄 때마다 세션 테이블이 생성되므로 각 장비에 여결된 현재 세션 수를 알 수 있습니다.

최소 접속 방식은 각 장비의 세션 수를 확인해 현재 세션이 가장 적게 연결된 장비로 서비스 요청을 보내는 방식입니다. 서비스별로 세션 수를 관리하면서 분산해주므로 각 장비에서 처리되는 활성화 세션 수가 비슷하게 분산되면서 부하를 분산하게 됩니다.

![alt text](./image/image256.png)

### 3. 해시

해시 방식은 서버의 부하를 고려하지 않고 클라이언트가 같은 서버에 지속적으로 접속하도록 하기 위해 사용하는 부하 분산 방식입니다.

서버 상태를 고려한는 것이 아닌 해시 알고리즘을 이용해 얻은 결과값으로 어떤 장비로 부하를 분산할지를 결정합니다. 알고리즘에 의한 계산 값에 의해 부하를 분산하므로 같은 알고리즘을 사용하면 항상 동일한 결과값을 가지고 서비스를 분산할 수있습니다.

이때 알고리즘 계산에 사용되는 값들을 지정할 수 있는데 주로 출발지 IP 주소 , 목적지 IP 주소 , 출발지 서비스 포트 , 목적지 서비스 포트를 사용합니다.
![alt text](./image/image257.png)

라운드 로빈이나 최소 접속 방식은 부하를 비교적 비슷한 비율로 분산시킬 수 있다는 장점이 있지만 동일한 출발지에서 로드 밸런서를 거친 서비스 요청이 처음에 분산된 서버와 그 다음 요청이 분산된 서버가 달라질 수 있어 각 서버에서 세션을 유지해야 하는 서비스는 정상적으로 서비스되지 않습니다.

그와 반대로 해시 방식은 알고리즘으로 계산한 값으로 서비스를 분산하므로 항상 동일한 장비로 서비스가 분산됩니다. 즉, 세션을 유지해야 하는 서비스에 적합한 분산 방식입니다.

하지만 알고리즘의 결과값이 특정한 값으로 치우치면 부하 분산 비율이 한쪽으로 치우칠 수도 있습니다. 최근에는 이런 경우가 별로 없지만 서버 애플리케이션 개발에 여러 대의 서버가 사용될 것을 고려하지 않고 개발한 경우, 이 방식을 사용해야 합니다.

흔히 이런 문제를 장바구니 문제라고 하는 데 A 서버에서 접속해 장바구니에 상품을 넣어두었는데 두 번째 접속할 때 B 서버로 접속되면 장바구니에 넣은 상품이 보이지 않을 때가 있습니다.

해시를 사용해야 하는 이유와 최소 접속 방식의 장점을 묶어 부하를 분산하는 방법도 있습니다. 라운드 로빈 방식이나 최소 접속 방식을 사용하면서 스티키(Sticky) 옵션을 주어 한번 접속한 커넥션을 지속적으로 유지하는 기법입니다.

처음 들어온 서비스 요청을 세션 테이블에 두고 같은 요청이 들어오면 같은 장비로 분산해 세션을 유지하는 방법입니다. 하지만 이렇게 하더라도 해당 세션 테이블에는 타임아웃이 있어 타임아웃 이후에는 분산되는 장비가 달라질 수 있다는 것을 고려해야 합니다. 스티키 옵션을 사용할 때는 애플리케이션 세션 유지 시간이나 일반 사용자들의 애플리케이션 행동 패턴을 충분히 감안해야 합니다.

따라서 부하 분산을 위한 알고리즘을 선택할 때는 제공되는 서비스의 특성을 잘 고려해 사용할 알고리즘을 결정해야 합니다. 그리고 각 알고리즘에 필요한 속성값도 함께 잘 고려해야만 적절한 부하 분산을 할 수 있습니다.

## 로드 밸런서 구성 방식

로드 밸런서의 구성 방식은 로드 밸런서의 구성 ㅜ이치에 따라 2가지로 나눌수 있습니다.

- 원암(One-Arm) 구성
- 인라인(inline) 구성

> 로드 밸런서의 2가지 구성 방식

![alt text](./image/image258.png)

원암 구성은 로드 밸런서가 중간 스위치 옆에 연결되는 구성이고 인라인 구성은 서버로 가는 경로상에 로드 밸런서가 연결되는 구성입니다.

여기서 주의할 점은 원암이라고 해서 단순히 로드 밸러서와 스위치 간에 연결되 인터페이스가 한 개라는 뜻은 아니라는 것입니다.

실질적으로 원암과 인라인의 구분은 서버로 가는 트래픽이 모두 로드 밸런서를 경유하는 지, 경유하지 않아도 되는지에 대한 트래픽 흐름으로 구분합니다.

원암 구성은 부하 분산을 수행하는 트래픽에 대해서만 로드밸런서를 경유하고 부하 부산을 수행하지 않는 트래픽은 로드 밸런서를 경유하지 않고 통신할 수 있습니다. <br/>
반면, 인라인 구성은 부하 분산을 포함한 모든 트래픽이 로드 밸런서를 경유하는 구성이 됩니다.

이런 구성 방식에 따라 앞에서 말한 트래픽이 흐르는 경로 , NAT 설정 , 이어서 다룰 로드밸런서의 동작 모드가 달라질 수 있습니다. 따라서 로드 밸런서의 구성 방식을 알아두는 것은로드밸런서를 이해하는데 매우 중요합니다.

### 1. 원암 구성

로드 밸런서의 원암(One Arm) 구성은 로드 밸런서가 스위치 옆에 있는 형태를 말합니다.

로드 밸런서가 스위치와 인터페이스 하나로 연결되어 있지만 원암 구성이 단순히 물리 인터페이스가 하나라는 뜻은 아닙니다. LACP 와 같은 다수의 인터페이스로 스위치와 연결된 경우에도 스위치 옆에 있는 구성이라면 동일하게 원암 구성이라고 합니다.

또한, 로드밸런서와 스위치 간 두 개 이상의 인터페이스를 LACP가 아닌 서로 다른 네트워크로 로드 밸런서와 구성한 경우에도 원암 구성이 될 수 있습니다. (이런 경우 투암이라고도 합니다.)

> 로드 밸런서와 스위치 간 인터페이스 수가 여러 개인 원암 구성의 예

![alt text](./image/image259.png)

이런 원암 구성에서는 서버로 들어가거나 나오는 트래픽이 로드 밸런서를 경유하거나 경유하지 않을 수 있습니다. 트래픽이 로드 밸런서를 경유하는지 여부는 부하 분산을 이용한 트래픽인지 여부로 구분할 수 있습니다.

먼저 원암 구조에서 부하 분산을 이용하는 트래픽 흐름에 대한 그림입니다.

> 부하 분산을 이용할 때는 로드 밸런서를 경유한다.

![alt text](./image/image260.png)

부하 분산을 이용하는 트래픽의 경우 부하 분산에 사용되는 서비스 IP 정보를 로드 밸런서가 가지고 있어 서버로 유입되는 트래픽은 먼저 로드 밸런서를 거칩니다.

로드 밸런서에서는 각 실제 서버로 트래픽을 분산하고 서버의 응답 트래픽은 다시 로드 밸런서를 거쳐 사용자에게 응답하게 됩니다. 원암 구조에서 서버의 응답 트래픽이 로드 밸런서를 다시 거치려면 로드 밸런서를 거칠 때, 서비스 IP 에 대해 실제 서버로 Destination NAT뿐만 아니라 서비스를 호출한 사용자 IP가 아니라 로드 밸런서가 가진 IP 로 Source NAT도 함께 이루어져야 합니다.

도는 Source NAT를 하지 않으려면 다음 장에서 알아 볼 로드 밸런서 동작 모드 중 DSR(Direct Server Return)을 사용하면 됩니다.

다음은 원암 구조에서 부하 분산을 이용하지 않는 트래픽 흐름의 그림입니다.

> 부하 분산을 이용하지 않을 때는 로드 밸런서를 경유하지 않는다.

![alt text](./image/image261.png)

로드 밸런서의 부하 분산을 이용하지 않는 트래픽은 원암 구성에서 굳이 로드 밸런서를 거치지 않아도 서버와 통신할 수 있습니다.

따라서 원암 구성에서는 로드 밸런서를 이용하는 서비스에 대해서만 로드 밸런서를 경유하므로 불필요한 트래픽이 로드 밸런서에 유입되지 않아 로드 밸런서의 부하를 줄일 수 있습니다.

스위치와 로드 밸런서 간의 대역폭을 최소화할 수 있고 대역폭이 부족할 때는 이 구간만 대역폭을 증설하면 되므로 다음의 인라인 방식보다 상대적으로 확장에 유리합니다.

원암 구성은 로드 밸런서 부하 감소는 물론 장애 영향도를 줄이기 위해서 사용됩니다. 로드 밸런서 장비에 장애가 발생하더라도 로드 밸런서를 거치지 않는 일반적인 서비스의 트래픽 흐름에는 문제가 없으므로 원암 구성은 로드 밸런서를 통과해야 하는 트래픽과 통과하지 않아도 되는 트래픽이 섞인 경우에 많이 사용됩니다.

### 2. 인라인 구성

로드 밸런서의 인라인 구성은 용어 그대로 밑의 그림처럼 로드 밸런서가 스위치에서 서버까지 가는 일직선상 경로에 있는 형태를 말합니다.

인라인 구성은 트래픽이 흐르는 경로에 로드 밸런서가 있어서 서버로 향하는 트래픽이 모두 로드 밸런서를 통과합니다.

서버 #1 , 서버 #2 가 있을 때 서버 #1 만 로드 밸런서를 통해 부하 분산을 받더라도 인라인 구조에서는 외부에서 서버까지의 경로가 로드 밸런서를 경유하도록 되어 있습니다.

![alt text](./image/image262.png)

모든 트래픽이 로드 밸런서를 경유하므로 로드 밸런서의 부하가 높아집니다. 특히 일반 L3 역할을 하는 스위치에 비해 로드 밸런서는 4계층 이상의 데이터를 처리하므로 처리 가능한 용량이 L3 장비보다 적으며 처리 용량이 커지면서 가격도 많이 상승하므로 로드 밸런서 부하에 따른 성능을 반드시 고려해야 합니다.

로드 밸런서에서 처리하지 않는 트래픽이 로드 밸런서를 거치더라도 그 부하는 크지 않습니다. 인라인으로 로드 밸런서를 선정할 때 로드 밸런싱 성능과 패킷 스루풋 성능을 구별해 디자인해야 합니다.

그 밖에 인라인 구성에서도 원암 구성과 동일하게 응답 트래픽이 로드 밸런서를 거치지 못하는 경우가 발생할 수 있습니다.

```
참고 : 물리적 원암 , 논리적 인라인

로드 밸런서의 원암과 인라인을 구분할 때 물리적으로는 원암 구성을 띠더라도 실제로는 인라인 구성인 경우도
있습니다.

로드 밸런서와 연결된 스위치상에서 VRF와 같은 가상화를 사용해 논리적으로 장비를 분리하는 경우가 예입니다.
VRF를 이용한 가상화까지 굳이 가지 않더라도 VLAN만으로도 인라인처럼 구성할 수 있습니다.

실제로 이런 경우는 물리적 구성이 아닌 장비의 논리적 구성도로 이해하면 일반적인 인라인 구성이 됩니다.
따라서 물리적 구성만 보고 원암과 인라인 구성을 구분하면 안됩니다.
```

## 로드 밸런서 동작 모드

로드 밸런서 구성 방식에 이어서 로드 밸런서 동작 모드에 대해 알아보겠습니다

- 트랜스패런트 (Transparent : TP) 또는 브릿지 (Bridge)
- 라우티드 (Routed)
- DSR (Direct Server Return)

### 1. 트랜스패런트 모드

트랜스패런트 (Transparent : 투명) 구성은 로드 밸런서 OSI 2계층 스위치 처럼 동작하는 구성입니다.

즉, 로드 밸런서에서 서비스하기 위해 사용하는 VIP 주소와 실제 서버가 동일한 네트워크를 사용하는 구성입니다. 트랜스패런트 구성은 기존에 사용하던 네트워크 대역을 그대로 사용하므로 로드 밸런서 도입으로 인한 IP 네트워크 재설계를 고려하지 않아도 되고 네트워크에 L2 스위치를 추가하는 것과 동일하게 기존 망의 트래픽 흐름에 미치는 영향 없이 로드 밸런서를 손쉽게 구성할 수 있습니다.

트랜스패런트 구성에서는 트래픽이 로드 밸런서를 지나더라도 부하 분산 서비스를 받는 트래픽인 경우에만 4계층 이상의 기능을 수행하며 부하 분산 서비스가 아닌 경우네느 기존 L2 스위치와 동일한 스위칭 기능만 수행합니다. 그래서 이 구성을 L2 구조라고 부르기도 합니다.

트랜스패런트 모드는 밑의 그림처럼 로드 밸런서 동작 모드 원암 과 인라인 구성에서 모두 사용할 수 있는 동작 모드입니다.

다만, 원암 구성에서는 응답 트래픽 경로 부분이 문제가 될 수 있어 Source NAT가 필요합니다. 여기서는 인라인 구성으로 트랜스패런트 모드를 살펴보겠습니다.

![alt text](./image/image263.png)

이제 트랜스패런트 모드에서 부하 분산 트래픽이 어떻게 흐르는지 알아보겠습니다.

> 트랜스패런드 모드에서 서비스 요청 시의 패킷 흐름

![alt text](./image/image264.png)

먼저 사용자는 서비스 IP인 로드 밸런서의 VIP 주소 10.10으로 서비스를 요청합니다. 로드 밸런서로 들어온 패킷은 목적지 IP 주소를 VIP에 바인딩되어 있는 실제 서버 IP 주소로 변경 (Rewrite) 하므로 목적지 IP 주소는 10.10 에서 10.11로 변경됩니다. 마찬가지로 목적지 MAC 주소도 실제 서버의 MAC 주소인 C가 됩니다.

로드 밸런서와 목적지 서버가 동일한 네트워크 대역이므로 L3 장비를 지날때 처럼 출발지 MAC 주소는 변경되지 않습니다. 서비스 요청 패킷의 목적지 정보가 변경되면 실제 서버로 패킷이 전달됩니다. 로드 밸런서에서 서비스를 위한 VIP 주소가 실제 서버의 IP 주소로 변경해 전송하므로 목적지 (Destination) NAT가 되었다고 합니다.

> 트랜스패런트 모드에서 서비스 응답시의 패킷 흐름

![alt text](./image/image265.png)

서버에서 사용자엑 응답할 때는 로드 밸런서를 지나면서 요청할 때와 반대로 출발지의 IP 주소가 실제 서버의 IP에서 VIP 주소로 변경되지만 목적지 MAC 주소는 변경되지 않습니다.

서버에서 응답할 때, 목적지 MAC 주소가 이미 게이트웨이의 MAC 주소를 갖고 있어 변경할 필요가 없기 때문입니다.

인라인 구성에서 로드 밸런서가 트랜스패런트 모드에서 동작할때, 게이트웨이 외부 사용자로부터 받은 서비스 요청을 처리하는 데는 문제가 없지만 동일 네트워크에서 서비스를 호출할 때는 서비스 응답이 로드 밸런서를 거치지 않을 수 있습니다.

로드 밸런서가 원암 구성인 경우에도 서비스 응답이 로드 밸런서를 거치지 않을 수 있고 이때 서비스에 문제가 발생할 수 있습니다. 응답 패킷이 로드 밸런서를 다시 거쳐 역변환되어야 정상적인 부하 분산이 가능하기 때문입니다.

### 2. 라우티드 모드

라우티드 구성은 이름에서도 알 수 있듯이 로드 밸런서가 라우팅 역할을 수행하는 모드입니다.

즉, 로드 밸런서를 기준으로 사용자 방향(Client Side)과 서버 방향 (Server Side)이 서로 다른 네트워크로 분리된 구성입니다. 로드 밸런서는 사용자 방향과 서버 방향의 네트워크를 라우팅으로 연결합니다. 라우티드 모드는 원암 구성과 인라인 구성에서 모두 구성할 수 있습니다.

> 원암과 인라인 구성에서도 모두 라우티드 모드 구성이 가능하다.

![alt text](./image/image266.png)

라우티드 모드는 보안 강화 목적으로 서버쪽 네트워크를 사설로 구성해 서버에 직접 접속하는 것을 막는 용도로 사용되기도 합니다.

그럼 라우티드 구성에서 로드 밸런서를 통한 트래픽이 어떻게 흐르는지 살펴보겠습니다.

> 라우티드 모드에서 서비스 요청 시의 패킷 흐름

![alt text](./image/image267.png)

사용자는 서비스 IP인 VIP 주소 10.10으로 서비스를 요청합니다. 로드 밸런서로 들어온 패킷은 목적지 IP 주소를 VIP 에 바인딩 된 실제 서버 IP 주소인 20.11로 변경합니다. 라우팅을 수행하면서 로드 밸런서를 통과하므로 일반 라우팅과 동일하게 출발지와 목적지 MAC 주소도 각각 A->D , B->C 로 변경됩니다.

목적지 IP 와 출발지/목적지 MAC이 변경된 패킷은 라우팅 테이블을 확인해 실제 서버로 전송됩니다. 이 과정에서 로드 밸런서는 서비스를 위한 VIP 에서 시제 서버의 IP 주소로 변경해 전송하므로 Destination NAT가 되었다고 합니다.

> 라우티드 모드에서 서비스 응답 시의 패킷 흐름

![alt text](./image/image268.png)

이번에는 서버에서 사용자로 전달되는 응답 패킷의 흐름을 살펴보겠습니다.

서버에서 사용자에게 응답하기 위해 패킷을 전송할 때는 출발지가 실제 서버의 IP 주소가 되고 목적지 IP는 원래 사용자의 IP 주소가 됩니다. 다만 목적지 IP 가 외부 네트워크이므로 목적지 MAC은 외부로 나가는 관문인 로드밸런서의 MAC 주소가 됩니다.

로드 밸런서로 들어온 패킷은 출발지 IP 주소를 실제 서버의 IP 인 20.11에서 사용자가 서비스를 위해 요청했던 VIP 인 10.10으로 변환합니다.

그리고 요청 트래픽과 마찬가지로 출발지와 목적지의 MAC주소를 변경한 후 사용자에게 응답 패킷을 전송합니다.

### 3. DSR 모드

DSR(Direct Server Return)은 명칭 그대로 사용자의 요청이 로드 밸런서를 통해 서버로 유입된 후에 다시 로드 밸런서를 통하기 않고 서버가 사용자에게 직접 응답하는 모드입니다.

로드 밸런서에는 응답 트래픽이 유입되지 않으므로 사용자가 요청하는 패킷에 대해서만 관여합니다. DSR 모드는 응답할 때, 로드 밸런서를 경유하지 않으므로 원암으로 구성합니다.

DSR모드는 L2 DSR과 L3 DSR로 구분되는데 L2 DSR은 실제 서버의 네트워크를 로드 밸런서가 가진 경우이며 L3 DSR 은 실제 서버의 네트워크 대역을 로드 밸런서가 가지지 않은 경우입니다. 즉, 로드 밸런서에서는 실제 서버까지의 통신이 L2 통신인지 , L3 통신인지에 따라 L2 DSR 과 L3 DSR로 나뉩니다.

DSR 모드에서는 요청 트래픽만 로드 밸런서를 통해 흐르므로 로드 밸런서 전체 트래픽이 감소해 로드 밸런서 부하가 감소합니다. 특히 일반겆인 서비스 트래픽인경우, 서비스 요청 패킷보다 서비스 응답 패킷의 크기가 더 크기 때문에 로드 밸런서의 트래픽 부하 감소에 효과적입니다.

응답 패킷의 크기가 클수록 이러한 부하 감소율은 더 커지게 되는데 예를 들어 사용자 요청에 의한 스트리밍 서비스와 같이 응답 패킷의 트래픽이 서비스에 필요한 대역폭의 대부분을 차지하는 경우에는 DSR 모드를 통해서 로드 밸런서를 경유하지 않고 응답 패킷의 트래픽을 전달하여 로드 밸런서 부하 감소 효과를 극대화할 수 있습니다.

반면, 이러한 효과가 있는 반면에 DSR 모드의 서비스 응답이 로드 밸런서를 경유하지 않으므로 문제가 발생했을때, 문제 확인이 어렵습니다. 다른 동작모드는 로드 밸런서 설정만 필요하지만 L2 DSR 과 L3 DSR 은 로드 밸런서 설정 외에 서버에서도 추가 설정이 필요합니다.

L3 DSR은 윈도 서버에서 지원하지 않으므로 서버팜에서 윈도 서버가 있는 경우 L3 DSR을 사용할 수 없습니다.

여기서는 L2 DSR 기준으로 다룹니다.
